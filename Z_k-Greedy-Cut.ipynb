{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from anytree import Node, RenderTree\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import io, sys, os\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "import cvxpy as cvx\n",
    "from scipy import linalg\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max-Cut (k=2) Partition: [-1.0, 1.0, 1.0, -1.0, 1.0]\n",
      "Max-Cut (k=2) Cut value: 15\n",
      "Max-3-Cut Partition: [0, 1, 2, 0, 1]\n",
      "Max-3-Cut Cut value: 16\n"
     ]
    }
   ],
   "source": [
    "def goemans_williamson_max_cut(W):\n",
    "    \"\"\"\n",
    "    Implements the Goemans-Williamson algorithm for max-cut approximation with vectorized operations\n",
    "    \n",
    "    Parameters:\n",
    "    W (numpy.ndarray): Symmetric weight matrix where W[i,j] is the weight of edge (i,j)\n",
    "    \n",
    "    Returns:\n",
    "    list: Binary partition of vertices (1 or -1 for each vertex)\n",
    "    float: Value of the cut\n",
    "    \"\"\"\n",
    "    n = W.shape[0]\n",
    "    \n",
    "    # Step 1: Solve the SDP relaxation using CVXPY\n",
    "    X = cvx.Variable((n, n), symmetric=True)\n",
    "    \n",
    "    # Vectorized constraints: X is PSD and diagonal elements are 1\n",
    "    constraints = [\n",
    "        X >> 0,  # X is positive semidefinite\n",
    "        cvx.diag(X) == np.ones(n)  # All diagonal elements equal to 1 (vectorized)\n",
    "    ]\n",
    "    \n",
    "    # Vectorized objective function\n",
    "    objective = 0.25 * cvx.sum(cvx.multiply(W, (1 - X)))\n",
    "    prob = cvx.Problem(cvx.Maximize(objective), constraints)\n",
    "    \n",
    "    # Solve the SDP\n",
    "    prob.solve()\n",
    "    \n",
    "    if prob.status != cvx.OPTIMAL:\n",
    "        raise ValueError(\"SDP relaxation failed to solve optimally\")\n",
    "    \n",
    "    X_opt = X.value\n",
    "    \n",
    "    # Step 2: Get the vector representation using eigendecomposition instead of Cholesky\n",
    "    eigvals, eigvecs = linalg.eigh(X_opt)\n",
    "    \n",
    "    # Filter out negative or very small eigenvalues (numerical issues)\n",
    "    tol = 1e-8\n",
    "    pos_indices = eigvals > tol\n",
    "    eigvals_filtered = eigvals[pos_indices]\n",
    "    eigvecs_filtered = eigvecs[:, pos_indices]\n",
    "    \n",
    "    # Construct the vectors: V = U * sqrt(D)\n",
    "    vectors = eigvecs_filtered @ np.diag(np.sqrt(eigvals_filtered))\n",
    "    \n",
    "    # Step 3: Random hyperplane rounding\n",
    "    # Generate a random unit vector\n",
    "    r = np.random.randn(vectors.shape[1])\n",
    "    r = r / np.linalg.norm(r)\n",
    "    \n",
    "    # Vectorized dot product and sign operation\n",
    "    signs = np.sign(vectors @ r)\n",
    "    \n",
    "    # Handle possible zeros in signs (unlikely but possible)\n",
    "    if np.any(signs == 0):\n",
    "        signs[signs == 0] = np.random.choice([-1, 1], size=np.sum(signs == 0))\n",
    "    \n",
    "    # Step 4: Calculate the cut value (using vectorized operations)\n",
    "    # Create a matrix where entry is 1 if vertices are in different partitions\n",
    "    different_partitions = (signs.reshape(-1, 1) != signs).astype(int)\n",
    "    \n",
    "    # Use only upper triangular part (to count each edge once)\n",
    "    upper_tri_mask = np.triu(np.ones((n, n)), k=1).astype(bool)\n",
    "    \n",
    "    # Multiply by the weight matrix and sum\n",
    "    cut_value = np.sum(W[upper_tri_mask] * different_partitions[upper_tri_mask])\n",
    "    \n",
    "    return signs.tolist(), cut_value\n",
    "\n",
    "def max_k_cut(W, k):\n",
    "    \"\"\"\n",
    "    Implements a generalized Goemans-Williamson algorithm for max-k-cut approximation with vectorized operations\n",
    "    \n",
    "    Parameters:\n",
    "    W (numpy.ndarray): Symmetric weight matrix where W[i,j] is the weight of edge (i,j)\n",
    "    k (int): Number of partitions\n",
    "    \n",
    "    Returns:\n",
    "    list: Partition assignment for each vertex (values 0 to k-1)\n",
    "    float: Value of the cut\n",
    "    \"\"\"\n",
    "    n = W.shape[0]\n",
    "    \n",
    "    # Step 1: Solve the SDP relaxation using CVXPY\n",
    "    X = cvx.Variable((n, n), symmetric=True)\n",
    "    \n",
    "    # Vectorized constraints\n",
    "    constraints = [\n",
    "        X >> 0,  # X is positive semidefinite\n",
    "        cvx.diag(X) == np.ones(n)  # All diagonal elements equal to 1 (vectorized)\n",
    "    ]\n",
    "    \n",
    "    # For k>2, the correct SDP relaxation (Frieze and Jerrum, 1997)\n",
    "    objective = cvx.sum(cvx.multiply(W, (1 - X/(k-1))))\n",
    "    prob = cvx.Problem(cvx.Maximize(objective), constraints)\n",
    "    \n",
    "    # Solve the SDP\n",
    "    prob.solve()\n",
    "    \n",
    "    if prob.status != cvx.OPTIMAL:\n",
    "        raise ValueError(\"SDP relaxation failed to solve optimally\")\n",
    "    \n",
    "    X_opt = X.value\n",
    "    \n",
    "    # Step 2: Get the vector representation using eigendecomposition\n",
    "    eigvals, eigvecs = linalg.eigh(X_opt)\n",
    "    \n",
    "    # Filter out negative or very small eigenvalues (numerical issues)\n",
    "    tol = 1e-8\n",
    "    pos_indices = eigvals > tol\n",
    "    eigvals_filtered = eigvals[pos_indices]\n",
    "    eigvecs_filtered = eigvecs[:, pos_indices]\n",
    "    \n",
    "    # Construct the vectors: V = U * sqrt(D)\n",
    "    vectors = eigvecs_filtered @ np.diag(np.sqrt(eigvals_filtered))\n",
    "    \n",
    "    # Step 3: Use k-means clustering for k>2 (more effective than random projections)\n",
    "    # Initialize with k-means++ for better starting positions\n",
    "    kmeans = KMeans(n_clusters=k, init='k-means++', n_init=10, random_state=42)\n",
    "    partition = kmeans.fit_predict(vectors)\n",
    "    \n",
    "    # Step 4: Calculate the cut value (vectorized)\n",
    "    # Create a matrix where entry is 1 if vertices are in different partitions\n",
    "    different_partitions = (partition.reshape(-1, 1) != partition).astype(int)\n",
    "    \n",
    "    # Use only upper triangular part (to count each edge once)\n",
    "    upper_tri_mask = np.triu(np.ones((n, n)), k=1).astype(bool)\n",
    "    \n",
    "    # Multiply by the weight matrix and sum\n",
    "    cut_value = np.sum(W[upper_tri_mask] * different_partitions[upper_tri_mask])\n",
    "    \n",
    "    return [partition.tolist(), cut_value]\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example symmetric matrix\n",
    "    W = np.array([\n",
    "        [0, 2, 3, 0, 1],\n",
    "        [2, 0, 1, 4, 2],\n",
    "        [3, 1, 0, 2, 0],\n",
    "        [0, 4, 2, 0, 3],\n",
    "        [1, 2, 0, 3, 0]\n",
    "    ])\n",
    "    \n",
    "    # For k=2 (original max-cut)\n",
    "    partition, cut_value = goemans_williamson_max_cut(W)\n",
    "    print(f\"Max-Cut (k=2) Partition: {partition}\")\n",
    "    print(f\"Max-Cut (k=2) Cut value: {cut_value}\")\n",
    "    \n",
    "    # For k=3\n",
    "    k = 3\n",
    "    partition, cut_value = max_k_cut(W, k)\n",
    "    print(f\"Max-{k}-Cut Partition: {partition}\")\n",
    "    print(f\"Max-{k}-Cut Cut value: {cut_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_guess(A, k, eval = 0, evec = 0, max_iter=1000):\n",
    "    n = A.shape[0]\n",
    "    # Calculate degrees of vertices\n",
    "    degrees = np.sum(A, axis=1)\n",
    "    # Create the degree matrix\n",
    "    D = np.diag(degrees)\n",
    "    # Calculate the Laplacian matrix\n",
    "    L = D - A\n",
    "    # Get the eigenvectors of the graph\n",
    "    eigvals, eigvecs = np.linalg.eig(L)\n",
    "    # Get the indices of the k largest eigenvectors\n",
    "    idx = np.argpartition(eigvals, 1-k)[1-k:]\n",
    "    # Get the eigenvectors corresponding to the k-1 largest eigenvalues\n",
    "    X = eigvecs[:, idx]\n",
    "    \n",
    "    if eval == 1:\n",
    "        print(\"Eigenvalues: \", eigvals[idx])\n",
    "    if evec == 1:\n",
    "        print(\"Eigenvectors: \", X)\n",
    "\n",
    "    # Initialize the centroids to the first k rows of X\n",
    "    centroids = X[:k]\n",
    "    # Initialize the cluster assignments to -1\n",
    "    clusters = np.full(n, -1)\n",
    "    for _ in range(max_iter):\n",
    "        # Assign each node to the nearest centroid\n",
    "        for i in range(n):\n",
    "            clusters[i] = np.argmin(np.linalg.norm(centroids - X[i], axis=1))\n",
    "        # Update the centroids\n",
    "        new_centroids = np.array([np.mean(X[clusters == i], axis=0) for i in range(k)])\n",
    "        # If the centroids haven't changed, return the clusters\n",
    "        if np.array_equal(centroids, new_centroids):\n",
    "            continue\n",
    "        centroids = new_centroids\n",
    "    \n",
    "    z = clusters.tolist()\n",
    "\n",
    "    result = 0\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            if z[i] != z[j]:\n",
    "                result += A[i][j]\n",
    "    return [z, float(result)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyFourierSearch:\n",
    "    def __init__(self, A, k):\n",
    "        # Validate inputs\n",
    "        if not isinstance(k, int) or not isinstance(A, np.ndarray):\n",
    "            raise ValueError(\"k must be an integer and A must be a numpy array\")\n",
    "        \n",
    "        n = A.shape[0]\n",
    "        if k > n:\n",
    "            raise ValueError(\"k must be less than n\")\n",
    "        \n",
    "        if A.shape[0] != A.shape[1]:\n",
    "            raise ValueError(\"A must be a square matrix\")\n",
    "        \n",
    "        if not np.all(A >= 0):\n",
    "            raise ValueError(\"A must contain only non-negative values\")\n",
    "        \n",
    "        if not np.allclose(A, A.T):\n",
    "            raise ValueError(\"A must be symmetric\")        \n",
    "        \n",
    "        # Calculate degrees of vertices\n",
    "        degrees = np.sum(A, axis=1)\n",
    "        \n",
    "        # Get the sorted indices based on degrees\n",
    "        sorted_indices = np.argsort(degrees)\n",
    "        \n",
    "        # Reorder the matrix A based on sorted indices\n",
    "        A = A[sorted_indices, :][:, sorted_indices]\n",
    "        \n",
    "        self.A = A #Reordered matrix greatly improves performance.\n",
    "        self.k = k\n",
    "        self.n = n\n",
    "        self.root = Node((\"root\", []), bound=float('inf'))\n",
    "\n",
    "    def get_address(self, node):\n",
    "        if node.is_root:\n",
    "            return []\n",
    "        return [node.name[0]] + node.parent.name[1] #Addresses are written in reverse to go from n down to 1.\n",
    "    \n",
    "    def value(self, node):\n",
    "        # Check if the node is an nth child of the root\n",
    "        if node.depth != self.n: #DEBUG LINE\n",
    "            return print(str(node.name[1]) + \" tried to be evaluated rather than bounded\")\n",
    "        \n",
    "        # Use the address directly\n",
    "        z = node.name[1]\n",
    "        \n",
    "        result = 0\n",
    "        for i in range(self.n):\n",
    "            for j in range(i+1,self.n):\n",
    "                if z[i] != z[j]:\n",
    "                    result += self.A[i][j]\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _bound(self, node):\n",
    "        \"\"\"\n",
    "        Computes the upper bound for a given node.\n",
    "        For now, it returns +infinity as a dummy upper bound.\n",
    "\n",
    "        :param node: The node for which to compute the upper bound.\n",
    "        :return: The computed upper bound.\n",
    "        \"\"\"\n",
    "        \n",
    "        address = node.name[1]\n",
    "        l = len(address)\n",
    "\n",
    "        if l <= 1: #To stop unnecessary computation at the start.\n",
    "            return [float('inf')]\n",
    "        \n",
    "        if l >= self.n: #DEBUG LINE\n",
    "            print(\"Address at \" + str(address) + \" is \" + str(l) + \" long\")\n",
    "            return [float('inf')]\n",
    "\n",
    "        \n",
    "        #Term 0 (|m_0|= 0)\n",
    "        Al = self.A[:self.n-l, :self.n-l] #Accounting for 0-indexing\n",
    "        b0x = self.k*0.5*np.sum(self.A)\n",
    "\n",
    "        # Convert address to a NumPy array\n",
    "        address_array = np.array(address)\n",
    "        # Create the Del matrix using broadcasting\n",
    "        Del = (address_array[:, None] == address_array[None, :]).astype(int)\n",
    "        b0y = (-1)*0.5*self.k*np.sum(np.multiply(Del,self.A[self.n-l:,self.n-l:,]))\n",
    "        \n",
    "        b0z = (-1)*0.5*np.sum(Al) #This looks like term 1 a lot, let's cancel out later.\n",
    "        \n",
    "        b0 = b0x+b0y+b0z\n",
    "        \"\"\"\n",
    "        Actually pretty good - greedy search looks promising!\n",
    "        Fourier sparsity => Smoothness => Low Variance => Greedy works well. \n",
    "        Need to make this more efficient. Can just store this 1 value at each layer and update it as we go down.\n",
    "        \"\"\"\n",
    "        return [float(b0/self.k)]\n",
    "    \n",
    "    def _branch(self, node):\n",
    "        #Only create one child for the root node, this is the beginnings of the overall branching simplification.\n",
    "        if node == self.root:\n",
    "            child = Node((0, [0]),parent=node)\n",
    "            child.bound = float('inf')\n",
    "            return\n",
    "\n",
    "        if len(node.name[1]) >= self.n: #DEBUG LINE\n",
    "            print(str(node.name[1]) + \" tried to have children\") \n",
    "            return #Is creating extra nodes beyond depth n, this is a temporary fix.\n",
    "        \n",
    "        if len(node.name[1]) == self.n-1:\n",
    "            for i in range(self.k):\n",
    "                child = Node((i, [i] + node.name[1]), parent=node)\n",
    "                child.bound = self.value(child)\n",
    "            return\n",
    "\n",
    "        # Create k children nodes\n",
    "        for i in range(self.k): \n",
    "            child = Node((i, [i] + node.name[1]), parent=node)\n",
    "            child.bound = sum(self._bound(child))\n",
    "            if node:\n",
    "                if child.bound > node.bound:\n",
    "                    child.bound = node.bound\n",
    "        return\n",
    "    \n",
    "    def search(self, node): # Add updates parameter with default value False\n",
    "        if len(node.name[1]) == self.n:\n",
    "            return [float(node.bound), node.name[1]]\n",
    "\n",
    "        self._branch(node)\n",
    "        best_child = max(node.children, key=lambda child: child.bound)\n",
    "        return self.search(best_child)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randdataset(N, m, D, dataset=None, seed=None, weights = None, name = None): \n",
    "\n",
    "    if seed is not None:\n",
    "            random.seed(seed)  # Set seed for reproducibility\n",
    "            np.random.seed(seed)\n",
    "            print(\"Seed set to \" + str(seed))\n",
    "\n",
    "    if dataset is None:  # Initialize the dataset dictionary\n",
    "        dataset = {}\n",
    "    \n",
    "    if m == 0:  # Base case: when no more graphs need to be generated\n",
    "        return [name, dataset]\n",
    "    \n",
    "    # Generate a random graph\n",
    "    G = nx.gnp_random_graph(N[-1], D[-1])  \n",
    "    if weights is not None:\n",
    "        for (u, v) in G.edges():\n",
    "            G[u][v]['weight'] = random.uniform(weights[0], weights[1])\n",
    "    \n",
    "    N = N[:-1]  # Remove the last element of N\n",
    "    D = D[:-1]  # Remove the last element of D\n",
    "    A = nx.to_numpy_array(G, dtype=float)  \n",
    "    \n",
    "    # Store it in the dataset\n",
    "    dataset[m - 1] = (A, G)  # Using m-1 to maintain consistency with the original for-loop\n",
    "\n",
    "    # Recursive call for the remaining m-1 graphs\n",
    "    return randdataset(N, m - 1, D, dataset, name = name)\n",
    "\n",
    "\n",
    "def test(data, k, showT = True, showG = True, name = None):\n",
    "    A = data[0]\n",
    "    G = data[1]\n",
    "\n",
    "    if showG:\n",
    "        num_vertices = G.number_of_nodes()\n",
    "        num_edges = G.number_of_edges()\n",
    "\n",
    "        # Calculate figure size based on the number of vertices and edges\n",
    "        width = 8 + num_vertices * 0.1\n",
    "        height = 6 + num_edges * 0.05\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(width, height))\n",
    "        nx.draw(G, ax=ax, with_labels=True, node_color='lightblue', edge_color='white', node_size=500, font_size=10, font_color='white')\n",
    "        plt.title(name, color='white')  # Set the title color to white\n",
    "        ax.set_facecolor('gray')  # Set the background color to black\n",
    "        ax.axis('off')  # Turn off the axis\n",
    "        fig.set_facecolor('gray')  # Set the figure background color to black\n",
    "        plt.show()\n",
    "        \n",
    "        pass\n",
    "\n",
    "    bb = GreedyFourierSearch(A, k)\n",
    "    Optima = bb.search(bb.root)\n",
    "    Max = float(round(Optima[0],2))\n",
    "    Arg = Optima[1]\n",
    "\n",
    "    count = 0\n",
    "    for pre, fill, node in RenderTree(bb.root): #fill is just a filler variable because of how RenderTree works.\n",
    "        count += 1\n",
    "        if showT:\n",
    "            if len(node.name[1]) < bb.n:\n",
    "                bounds = bb._bound(node)  # Get the bounds [b1, b2, b3]\n",
    "                print(f'{pre} {node.depth} {node.name[1]} {bounds}')\n",
    "                #print(f'{pre} {node.depth} {node.name[1]} {float(round(node.bound,2))}')\n",
    "            else: print(f'{pre} {node.depth} {node.name[1]} {float(round(bb.value(node),2))}')\n",
    "\n",
    "    specguess = spectral_guess(A, k)\n",
    "\n",
    "    result = [Max,Arg,specguess[1],specguess[0]]\n",
    "\n",
    "    if showG:\n",
    "        present(result, eff = True, max = True)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def multitest(dataset, K, showG = True, showT = False, i=0, results=None):  \n",
    "    if results is None:  \n",
    "        results = [[], [], [], []]  # Initialize the results list\n",
    "\n",
    "    if i >= len(K):  # Correctly compare integer i to length of K\n",
    "        return results\n",
    "    \n",
    "    # Call test and store its result\n",
    "    result = test(dataset[1][i], K[i], showG = showG, showT = showT, name = dataset[0])\n",
    "    testmax = result[0]\n",
    "    testarg = result[1]\n",
    "    testspec1 = result[2]\n",
    "    testspec0 = result[3]\n",
    "\n",
    "    # Append the result (percentage pruned) to results\n",
    "    results[0].append(testmax)\n",
    "    results[1].append(testarg)\n",
    "    results[2].append(testspec1)\n",
    "    results[3].append(testspec0)\n",
    "    \n",
    "    # Continue recursion\n",
    "    return multitest(dataset, K, showG, showT, i+1, results)  # Pass the results list down the recursion\n",
    "\n",
    "def present(result, eff = True, max = False):\n",
    "    if eff:\n",
    "        print(\"The spectral guess for the graph is: \" + str(result[2]) + \" at \" + str(result[3]))\n",
    "    if max:\n",
    "        print(\"The greedy guess for the graph is: \" + str(result[0]) + \" at \" + str(result[1]))\n",
    "    return\n",
    "\n",
    "def multipresent(results, eff = True, max = False, ):\n",
    "    if eff:\n",
    "        print(\"The spectral guess for the graph is: \" + str(results[2]) + \" at \" + str(results[3]))\n",
    "    if max:\n",
    "        print(\"The greedy guess for the graph is: \" + str(results[0]) + \" at \" + str(results[1]))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(results):\n",
    "    greedy = np.array(results[0])\n",
    "    spectral = np.array(results[2])\n",
    "    mean = float(round(np.mean(greedy-spectral), 2))\n",
    "    median = float(round(np.median(greedy-spectral), 2))\n",
    "    std = float(round(np.std(greedy-spectral), 2))\n",
    "    return [mean, median, std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = randdataset([100], 1, [0.75], name = '10 Vertex Graph with 0.3 edge probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Results \u001b[38;5;241m=\u001b[39m \u001b[43mmultitest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGreedy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGM\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshowG\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshowT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m multipresent(Results, eff \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mmax\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 98\u001b[0m, in \u001b[0;36mmultitest\u001b[1;34m(dataset, K, Greedy, spec, GM, showG, showT, i, results)\u001b[0m\n\u001b[0;32m     96\u001b[0m result \u001b[38;5;241m=\u001b[39m test(dataset[\u001b[38;5;241m1\u001b[39m][i], K[i], showG \u001b[38;5;241m=\u001b[39m showG, showT \u001b[38;5;241m=\u001b[39m showT, name \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Greedy:\n\u001b[1;32m---> 98\u001b[0m     testmax \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     99\u001b[0m     testarg \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec:\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "Results = multitest(X, [4], Greedy =1, spec = 1, GM = 1, showG = 0, showT = 0)\n",
    "multipresent(Results, eff = 1, max = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 19, 15, 15, 19, 17, 16, 15, 16, 17, 15, 17, 20, 17, 20, 19, 15, 17, 20, 20, 18, 16, 17, 17, 19, 19, 19, 15, 18, 18, 19, 17, 16, 16, 16, 20, 16, 16, 19, 20, 18, 17, 17, 20, 17, 16, 17, 20, 15, 18]\n"
     ]
    }
   ],
   "source": [
    "#Parameters for Dataset Construction\n",
    "#Size of each dataset (number of graphs)\n",
    "m=50\n",
    "\n",
    "# Number of vertices for graphs in a certain range\n",
    "v = 100\n",
    "V = 100\n",
    "N = [random.randint(v,V) for i in range(m)]\n",
    "print(N)\n",
    "\n",
    "# Weight range for the weighted graphs\n",
    "w = 0.1\n",
    "W = 1\n",
    "\n",
    "# Special Parameters\n",
    "eps = 0.05 #Should be between 0.01 and 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unweighted Datasets\n",
    "UnweightedDatasets = {}\n",
    "UnweightedDatasets['Isolated'] = randdataset(N, m, [1/i for i in N], name='Isolated')\n",
    "UnweightedDatasets['Transitioning to Connectivity'] = randdataset(N, m, [float(np.log2(i)/i) for i in N], name='Transitioning to Connectivity')\n",
    "UnweightedDatasets['Extremely Sparse'] = randdataset(N, m, [float(1/np.sqrt(i)) for i in N], name='Extremely Sparse')\n",
    "UnweightedDatasets['Very Sparse'] = randdataset(N, m, [0.1 for i in N], name='Very Sparse')\n",
    "UnweightedDatasets['Moderately Sparse'] = randdataset(N, m, [0.25 for i in N], name='Moderately Sparse')\n",
    "UnweightedDatasets['Moderately Dense'] = randdataset(N, m, [0.5 for i in N], name='Moderately Dense')\n",
    "UnweightedDatasets['Very Dense'] = randdataset(N, m, [0.75 for i in N], name='Very Dense')\n",
    "#UnweightedDatasets['Extremely Dense'] = randdataset(N, m, [1-eps for i in N], name='Extremely Dense')\n",
    "#UnweightedDatasets['Complete'] = randdataset(N, m, [1 for i in N], name='Complete')\n",
    "\n",
    "# Weighted Datasets\n",
    "WeightedDatasets = {}\n",
    "WeightedDatasets['Isolated'] = randdataset(N, m, [1/i for i in N], weights=(w, W), name='Isolated')\n",
    "WeightedDatasets['Transitioning to Connectivity'] = randdataset(N, m, [float(np.log2(i)/i) for i in N], weights=(w, W), name='Transitioning to Connectivity')\n",
    "WeightedDatasets['Extremely Sparse'] = randdataset(N, m, [float(1/np.sqrt(i)) for i in N], weights=(w, W), name='Extremely Sparse')\n",
    "WeightedDatasets['Very Sparse'] = randdataset(N, m, [0.1 for i in N], weights=(w, W), name='Very Sparse')\n",
    "WeightedDatasets['Moderately Sparse'] = randdataset(N, m, [0.25 for i in N], weights=(w, W), name='Moderately Sparse')\n",
    "WeightedDatasets['Moderately Dense'] = randdataset(N, m, [0.5 for i in N], weights=(w, W), name='Moderately Dense')\n",
    "WeightedDatasets['Very Dense'] = randdataset(N, m, [0.75 for i in N], weights=(w, W), name='Very Dense')\n",
    "#WeightedDatasets['Extremely Dense'] = randdataset(N, m, [1-eps for i in N], weights=(w, W), name='Extremely Dense')\n",
    "#WeightedDatasets['Complete'] = randdataset(N, m, [1 for i in N], weights=(w, W), name='Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Soap Suds\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\_core\\fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\Soap Suds\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\_core\\_methods.py:139: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Isolated\n",
      "Dataset: Transitioning to Connectivity\n",
      "Dataset: Extremely Sparse\n",
      "Dataset: Very Sparse\n",
      "Dataset: Moderately Sparse\n",
      "Dataset: Moderately Dense\n",
      "Dataset: Very Dense\n",
      "Dataset: Isolated\n",
      "Dataset: Transitioning to Connectivity\n",
      "Dataset: Extremely Sparse\n",
      "Dataset: Very Sparse\n",
      "Dataset: Moderately Sparse\n",
      "Dataset: Moderately Dense\n",
      "Dataset: Very Dense\n"
     ]
    }
   ],
   "source": [
    "# Testing of the algorithm over various datasets for the two-cut problem\n",
    "U2Cut = {}\n",
    "for key in UnweightedDatasets.keys():\n",
    "    U2Cut[key] = multitest(UnweightedDatasets[key], [2 for i in range(m)], showG = False)\n",
    "    print(\"Dataset: \" + key)\n",
    "\n",
    "W2Cut = {}\n",
    "for key in WeightedDatasets.keys():\n",
    "    W2Cut[key] = multitest(WeightedDatasets[key], [2 for i in range(m)], showG = False)\n",
    "    print(\"Dataset: \" + key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Isolated\n",
      "Dataset: Transitioning to Connectivity\n",
      "Dataset: Extremely Sparse\n",
      "Dataset: Very Sparse\n",
      "Dataset: Moderately Sparse\n",
      "Dataset: Moderately Dense\n",
      "Dataset: Very Dense\n",
      "Dataset: Isolated\n",
      "Dataset: Transitioning to Connectivity\n",
      "Dataset: Extremely Sparse\n",
      "Dataset: Very Sparse\n",
      "Dataset: Moderately Sparse\n",
      "Dataset: Moderately Dense\n",
      "Dataset: Very Dense\n"
     ]
    }
   ],
   "source": [
    "# Testing of the algorithm over various datasets for the three-cut problem\n",
    "U3Cut = {}\n",
    "for key in UnweightedDatasets.keys():\n",
    "    U3Cut[key] = multitest(UnweightedDatasets[key], [3 for i in range(m)], showG = False)\n",
    "    #U3Cut[key] = [None]\n",
    "    print(\"Dataset: \" + key)\n",
    "\n",
    "W3Cut = {}\n",
    "for key in WeightedDatasets.keys():\n",
    "    W3Cut[key] = multitest(WeightedDatasets[key], [3 for i in range(m)], showG = False)\n",
    "    #W3Cut[key] = [None]\n",
    "    print(\"Dataset: \" + key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Isolated\n",
      "Dataset: Transitioning to Connectivity\n",
      "Dataset: Extremely Sparse\n",
      "Dataset: Very Sparse\n",
      "Dataset: Moderately Sparse\n",
      "Dataset: Moderately Dense\n",
      "Dataset: Very Dense\n",
      "Dataset: Isolated\n",
      "Dataset: Transitioning to Connectivity\n",
      "Dataset: Extremely Sparse\n",
      "Dataset: Very Sparse\n",
      "Dataset: Moderately Sparse\n",
      "Dataset: Moderately Dense\n",
      "Dataset: Very Dense\n"
     ]
    }
   ],
   "source": [
    "# Testing of the algorithm over various datasets for the four-cut problem\n",
    "U4Cut = {}\n",
    "for key in UnweightedDatasets.keys():\n",
    "    U4Cut[key] = multitest(UnweightedDatasets[key], [4 for i in range(m)], showG = False)\n",
    "    #U4Cut[key] = [None]\n",
    "    print(\"Dataset: \" + key)\n",
    "\n",
    "W4Cut = {}\n",
    "for key in WeightedDatasets.keys():\n",
    "    W4Cut[key] = multitest(WeightedDatasets[key], [4 for i in range(m)], showG = False)\n",
    "    #W4Cut[key] = [None]\n",
    "    print(\"Dataset: \" + key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "UCut = {2: U2Cut, 3: U3Cut, 4: U4Cut}\n",
    "WCut = {2: W2Cut, 3: W3Cut, 4: W4Cut}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to hold the statis\n",
    "UStats = {2: [], 3: [], 4: []}\n",
    "WStats = {2: [], 3: [], 4: []}\n",
    "\n",
    "# Populate the dictionary with the performance statistics\n",
    "for key in UnweightedDatasets.keys():\n",
    "    UStats[2].append(statistics(UCut[2][key]))\n",
    "    UStats[3].append(statistics(UCut[3][key]))\n",
    "    UStats[4].append(statistics(UCut[4][key]))\n",
    "    WStats[2].append(statistics(WCut[2][key]))\n",
    "    WStats[3].append(statistics(WCut[3][key]))\n",
    "    WStats[4].append(statistics(WCut[4][key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unweighted datasets performance\n",
    "U2Performance = pd.DataFrame(UStats[2], index=UnweightedDatasets.keys())\n",
    "U2Performance.columns = ['Mean', 'Median', 'Standard Deviation']\n",
    "U2Performance.name = \"k = 2, Unweighted\"\n",
    "\n",
    "U3Performance = pd.DataFrame(UStats[3], index=UnweightedDatasets.keys())\n",
    "U3Performance.columns = ['Mean', 'Median', 'Standard Deviation']\n",
    "U3Performance.name = \"k = 3, Unweighted\"\n",
    "\n",
    "U4Performance = pd.DataFrame(UStats[4], index=UnweightedDatasets.keys())\n",
    "U4Performance.columns = ['Mean', 'Median', 'Standard Deviation']\n",
    "U4Performance.name = \"k = 4, Unweighted\"\n",
    "\n",
    "# Weighted datasets performance\n",
    "W2Performance = pd.DataFrame(WStats[2], index=WeightedDatasets.keys())\n",
    "W2Performance.columns = ['Mean', 'Median', 'Standard Deviation']\n",
    "W2Performance.name = \"k = 2, Weighted\"\n",
    "\n",
    "W3Performance = pd.DataFrame(WStats[3], index=WeightedDatasets.keys())\n",
    "W3Performance.columns = ['Mean', 'Median', 'Standard Deviation']\n",
    "W3Performance.name = \"k = 3, Weighted\"\n",
    "\n",
    "W4Performance = pd.DataFrame(WStats[4], index=WeightedDatasets.keys())\n",
    "W4Performance.columns = ['Mean', 'Median', 'Standard Deviation']\n",
    "W4Performance.name = \"k = 4, Weighted\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2, Unweighted\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Isolated</th>\n",
       "      <td>22.30</td>\n",
       "      <td>23.5</td>\n",
       "      <td>4.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transitioning to Connectivity</th>\n",
       "      <td>88.36</td>\n",
       "      <td>73.0</td>\n",
       "      <td>48.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extremely Sparse</th>\n",
       "      <td>56.34</td>\n",
       "      <td>58.0</td>\n",
       "      <td>74.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Very Sparse</th>\n",
       "      <td>84.86</td>\n",
       "      <td>55.5</td>\n",
       "      <td>94.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moderately Sparse</th>\n",
       "      <td>85.30</td>\n",
       "      <td>-57.0</td>\n",
       "      <td>259.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moderately Dense</th>\n",
       "      <td>515.50</td>\n",
       "      <td>663.5</td>\n",
       "      <td>528.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Very Dense</th>\n",
       "      <td>1341.56</td>\n",
       "      <td>1509.5</td>\n",
       "      <td>403.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Mean  Median  Standard Deviation\n",
       "Isolated                         22.30    23.5                4.66\n",
       "Transitioning to Connectivity    88.36    73.0               48.62\n",
       "Extremely Sparse                 56.34    58.0               74.45\n",
       "Very Sparse                      84.86    55.5               94.44\n",
       "Moderately Sparse                85.30   -57.0              259.23\n",
       "Moderately Dense                515.50   663.5              528.03\n",
       "Very Dense                     1341.56  1509.5              403.93"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2, Weighted\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Isolated</th>\n",
       "      <td>23.60</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transitioning to Connectivity</th>\n",
       "      <td>83.37</td>\n",
       "      <td>76.5</td>\n",
       "      <td>56.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extremely Sparse</th>\n",
       "      <td>78.56</td>\n",
       "      <td>62.5</td>\n",
       "      <td>93.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Very Sparse</th>\n",
       "      <td>87.46</td>\n",
       "      <td>66.0</td>\n",
       "      <td>82.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moderately Sparse</th>\n",
       "      <td>32.60</td>\n",
       "      <td>-60.5</td>\n",
       "      <td>230.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moderately Dense</th>\n",
       "      <td>447.83</td>\n",
       "      <td>280.5</td>\n",
       "      <td>527.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Very Dense</th>\n",
       "      <td>1214.45</td>\n",
       "      <td>1511.5</td>\n",
       "      <td>504.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Mean  Median  Standard Deviation\n",
       "Isolated                         23.60    24.0                5.28\n",
       "Transitioning to Connectivity    83.37    76.5               56.83\n",
       "Extremely Sparse                 78.56    62.5               93.59\n",
       "Very Sparse                      87.46    66.0               82.93\n",
       "Moderately Sparse                32.60   -60.5              230.18\n",
       "Moderately Dense                447.83   280.5              527.28\n",
       "Very Dense                     1214.45  1511.5              504.18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 3, Unweighted\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Isolated</th>\n",
       "      <td>26.54</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transitioning to Connectivity</th>\n",
       "      <td>95.10</td>\n",
       "      <td>99.5</td>\n",
       "      <td>48.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extremely Sparse</th>\n",
       "      <td>110.02</td>\n",
       "      <td>112.0</td>\n",
       "      <td>70.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Very Sparse</th>\n",
       "      <td>147.94</td>\n",
       "      <td>148.0</td>\n",
       "      <td>93.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moderately Sparse</th>\n",
       "      <td>185.72</td>\n",
       "      <td>164.0</td>\n",
       "      <td>166.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moderately Dense</th>\n",
       "      <td>507.66</td>\n",
       "      <td>400.0</td>\n",
       "      <td>434.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Very Dense</th>\n",
       "      <td>1204.40</td>\n",
       "      <td>1146.5</td>\n",
       "      <td>657.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Mean  Median  Standard Deviation\n",
       "Isolated                         26.54    26.0                6.56\n",
       "Transitioning to Connectivity    95.10    99.5               48.53\n",
       "Extremely Sparse                110.02   112.0               70.97\n",
       "Very Sparse                     147.94   148.0               93.52\n",
       "Moderately Sparse               185.72   164.0              166.02\n",
       "Moderately Dense                507.66   400.0              434.28\n",
       "Very Dense                     1204.40  1146.5              657.53"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 3, Weighted\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Isolated</th>\n",
       "      <td>28.15</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transitioning to Connectivity</th>\n",
       "      <td>86.21</td>\n",
       "      <td>94.0</td>\n",
       "      <td>43.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extremely Sparse</th>\n",
       "      <td>119.11</td>\n",
       "      <td>114.0</td>\n",
       "      <td>77.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Very Sparse</th>\n",
       "      <td>125.65</td>\n",
       "      <td>129.0</td>\n",
       "      <td>68.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moderately Sparse</th>\n",
       "      <td>191.50</td>\n",
       "      <td>172.5</td>\n",
       "      <td>183.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moderately Dense</th>\n",
       "      <td>595.70</td>\n",
       "      <td>462.5</td>\n",
       "      <td>499.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Very Dense</th>\n",
       "      <td>1336.33</td>\n",
       "      <td>1413.5</td>\n",
       "      <td>653.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Mean  Median  Standard Deviation\n",
       "Isolated                         28.15    26.0                8.14\n",
       "Transitioning to Connectivity    86.21    94.0               43.12\n",
       "Extremely Sparse                119.11   114.0               77.90\n",
       "Very Sparse                     125.65   129.0               68.51\n",
       "Moderately Sparse               191.50   172.5              183.08\n",
       "Moderately Dense                595.70   462.5              499.42\n",
       "Very Dense                     1336.33  1413.5              653.06"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 4, Unweighted\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Isolated</th>\n",
       "      <td>30.88</td>\n",
       "      <td>30.5</td>\n",
       "      <td>8.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transitioning to Connectivity</th>\n",
       "      <td>87.42</td>\n",
       "      <td>91.0</td>\n",
       "      <td>35.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extremely Sparse</th>\n",
       "      <td>114.38</td>\n",
       "      <td>123.5</td>\n",
       "      <td>58.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Very Sparse</th>\n",
       "      <td>126.02</td>\n",
       "      <td>126.0</td>\n",
       "      <td>67.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moderately Sparse</th>\n",
       "      <td>281.90</td>\n",
       "      <td>247.5</td>\n",
       "      <td>195.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moderately Dense</th>\n",
       "      <td>497.34</td>\n",
       "      <td>447.0</td>\n",
       "      <td>350.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Very Dense</th>\n",
       "      <td>965.50</td>\n",
       "      <td>872.5</td>\n",
       "      <td>585.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Mean  Median  Standard Deviation\n",
       "Isolated                        30.88    30.5                8.78\n",
       "Transitioning to Connectivity   87.42    91.0               35.85\n",
       "Extremely Sparse               114.38   123.5               58.92\n",
       "Very Sparse                    126.02   126.0               67.04\n",
       "Moderately Sparse              281.90   247.5              195.79\n",
       "Moderately Dense               497.34   447.0              350.38\n",
       "Very Dense                     965.50   872.5              585.11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 4, Weighted\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Isolated</th>\n",
       "      <td>31.93</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transitioning to Connectivity</th>\n",
       "      <td>81.99</td>\n",
       "      <td>76.0</td>\n",
       "      <td>42.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extremely Sparse</th>\n",
       "      <td>116.10</td>\n",
       "      <td>126.5</td>\n",
       "      <td>63.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Very Sparse</th>\n",
       "      <td>102.66</td>\n",
       "      <td>108.0</td>\n",
       "      <td>54.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moderately Sparse</th>\n",
       "      <td>288.33</td>\n",
       "      <td>230.5</td>\n",
       "      <td>209.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moderately Dense</th>\n",
       "      <td>573.31</td>\n",
       "      <td>436.0</td>\n",
       "      <td>360.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Very Dense</th>\n",
       "      <td>1034.98</td>\n",
       "      <td>941.5</td>\n",
       "      <td>544.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Mean  Median  Standard Deviation\n",
       "Isolated                         31.93    36.0               10.75\n",
       "Transitioning to Connectivity    81.99    76.0               42.78\n",
       "Extremely Sparse                116.10   126.5               63.30\n",
       "Very Sparse                     102.66   108.0               54.17\n",
       "Moderately Sparse               288.33   230.5              209.66\n",
       "Moderately Dense                573.31   436.0              360.53\n",
       "Very Dense                     1034.98   941.5              544.94"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display DataFrames with their names\n",
    "print(U2Performance.name)\n",
    "display(U2Performance)\n",
    "\n",
    "print(W2Performance.name)\n",
    "display(W2Performance)\n",
    "\n",
    "print(U3Performance.name)\n",
    "display(U3Performance)\n",
    "\n",
    "print(W3Performance.name)\n",
    "display(W3Performance)\n",
    "\n",
    "print(U4Performance.name)\n",
    "display(U4Performance)\n",
    "\n",
    "print(W4Performance.name)\n",
    "display(W4Performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
